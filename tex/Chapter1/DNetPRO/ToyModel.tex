\documentclass{standalone}

\begin{document}

\section[Toy Model]{Synthetic dataset benchmark}\label{toy}

We firstly tested the DNetPRO method with synthetic data, consisting in a small set of discriminating variables together with a large number of \quotes{noisy} variables.
Fixing the number of informative features and classes we test the DNetPRO efficiency on the features extraction, compared to the results obtained by individually single features ranking (\emph{Kbest} feature selection).

To simulate a synthetic \quotes{gene expression dataset}, with a large number of variables and a much smaller number of samples, we use the toy \href{https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html}{model generator} provided by the \emph{scikit-learn}~\cite{scikit-learn} python package.
This model generator allows to set a precise number of classes and it distinguishes between \emph{informative features}, i.e. features which easily separate the class populations, and \emph{redundant features}, i.e. features which represent noise in our problem.
The number of informative features should be realistically small compared to the noise, so in our simulations we chose to introduce at least a 10\% of informative features in the whole dataset.

% TODO: simulations and results

%Method description.
%Efficiency on a biological toy model.



\end{document}