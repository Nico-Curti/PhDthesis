\documentclass{standalone}

\begin{document}

\chapter[Feature Selection]{Feature Selection - DNetPRO algorithm}\label{chapter1:featsel}

%Introduction to feature selection problem and theoretical background.

%Focus on biological Big Data and problems related.

After the end of the Human Genome Project (HGP, 2003)~\cite{McKinney2012} there were growing interest on biological data and their analysis.
At the same time, the availability of this type of data increased exponentially with the technological improvement of data extractors (High-Throughput technologies)~\cite{Reuter2015} and the lower production costs.
These are the main factors that allow us to go into the new scientific era of Big Data.
Biological Big Data works with very large and complex datasets which are typically impossible to store, handle and analyze using standard computers and techniques~\cite{Kumari2014}.
Just think that we need around 140~GB for the storage of the DNA of a single person and an Array Express, a compendium of public gene expression data, has more than 1.3 million of genomes which have been collected in more than \numprint{45000} experiments~\cite{Greene2014}.
Since the number of available data is getting greater, we need to design several storage databases to organize, classify and, moreover, extract information from them.
The Bioinformatics European Institute (EBI) at Hinxton (UK), which is part of the European Laboratory of Biological Molecular and one of the biggest repositories of biological data, stores 20 petabytes of genomic data and proteomics back-ups.
The amount of the genomics data is only 2 petabytes, and it doubles every year: it is not worth to remark that these quantities represent about a tenth of data stored by CERN of Ginevra~\cite{Marx2013}.
In contrary, the ability of processing data and the computational techniques of analysis do not grow in the same way.
Therefore, the gap between the growth of available data and our ability to work with them is getting bigger.

From a computational point-of-view, the Bioinformatics new-science is looking for new methods to analyze these large amount of data.
Common Machine Learning methods, i.e computational algorithms able to find significant patterns into large quantities of data, need to be optimized and modified to increase their computational and statistical performances.
To improve the computational time, we need to extend existing methods and algorithms, and to develop new dimensionality reduction techniques.
In Machine Learning, in fact, as the dimensionality of the data increases, the amount of data required to perform a reliable analysis grows exponentially\footnote{
  High dimensional data tends to become very sparse and as result it is hard to perform robust statistical evaluation on it.
  This phenomena is commonly called \quotes{curse of dimensionality}~\cite{bellman1961adaptive}.
}.
Dimensionality reduction techniques are methods able to find the more significant variables of a given problem or a combination of them, where \quotes{significant} means that these few variables (or features) preserve the information about the problem as much as possible.
High-dimensional omics data (e.g. transcriptomics through microarray or NGS, epigenomics, SNP profiling, proteomics and metabolomics, but also metagenomics of gut microbiota) pose enormous challenges on how to extract useful information from them.
One of the prominent problems is to extract low-dimensional sets of variables –~signatures~– for classification and diagnostic purposes, or to better stratify patients for personalized intervention strategies based on their molecular profile~\cite{Scotlandi2009, Chan2011, Johnson2017, Beckmann2016ReconcilingEM}.


\begin{figure}[htbp]
\centering
\def\svgwidth{0.4\textwidth}
\input{./img/distributions.pdf_tex}
\qquad\qquad
\def\svgwidth{0.4\textwidth}
\input{./img/expression.pdf_tex}
\caption{(\textbf{a}) An example in which single-parameter classification fails in predicting higher-dimension classification performance.
Both parameters (\emph{feature1} and \emph{feature2}) badly classify in 1-D, but they have a very good performance in 2D.
Moreover, classification can be easily interpreted in terms of relative higher/lower expression of both probes.
(\textbf{b}) Activity of a biological feature (e.g. a gene) as a function of its expression level:
top) monotonically increasing, often also discretized to an on/off state;
center, bottom) \quotes{windowed} behavior, in which there are two or more activity states that do not depend monotonically on expression level.
X axis: expression level, Y axis, biological state (arbitrary scales).
}
\label{fig:example}
\end{figure}

Many approaches are used to face such problems~\cite{Guyon2002}, as Elastic Net~\cite{Hughey2015}, Support Vector Machine, K-nearest Neighbor, Neural Network and Random Forest~\cite{Pang2012}.
Some methods select variables using single-variable scoring methods~\cite{Eckhard2012, Hocking1976} (e.g. Student's t test for a two-class comparison), while others search for projections in lower-dimensional variable spaces, but all these approaches could fail even in simple 2-dimensional situations (Fig.~\ref{fig:example}).
As shown in Fig.~\ref{fig:example}~(a), both variables perform poorly taken singularly, but their performance becomes optimal taking them together (in terms of linear separation of the two classes).

It is known that complex separation surfaces characterize classification tasks associated to image and speech recognition, for which Deep Networks are used successfully in recent times, but in many cases biological data, such as gene or protein expression, are more likely characterized by an up/down-regulation behavior (as shown in Fig.~\ref{fig:example}~(b) top), while more complex behaviors (e.g. a \quotes{windowed} optimal range of activity, Fig.~\ref{fig:example}~(b) bottom) are much less likely.
Discriminant-based methods (and logistic regression methods alike) can very likely provide good classification performances in these cases, if applied in at least two-dimensional spaces.
The \quotes{linearity} of these methods (that generate very simple class separation surfaces, i.e. linear or quadratic) also ensures that a \quotes{buildup} of a signature based on lower-dimensional signatures can be done.

These considerations are relevant in particular for microarray data, where we face on few samples compared to a huge amount of variables (gene probes).
This kind of problem, often called \quotes{large $N$, small $S$} problem (where $N$ is the number of features, i.e variables, and $S$ is the number of samples), tends to be prone to overfitting\footnote{
  A solution to a problem is classified as \quotes{overfitted} if small fluctuations on the data variance produces classification errors.
  This problem arises when the model perfectly fits a small training set, but it is not able to generalize to a large amount of test samples (generalization).
} and they are classified to ill-posed.
The difficulty on the features extraction can also increase due to noisy variables that can drastically affect the machine learning algorithm.
It is often difficult to discriminate between noisy and significant variables, even more as the number of variables increases.

In this thesis we propose a new method of feature selection - DNetPRO, \emph{Discriminant Analysis with Network PROcessing} - developed to outperform the problems mentioned above.
Our method is designed to gene-expression data analysis and it was tested against the most common feature selection techniques.
The method was already applied on gene-expression datasets, but my work focused on its benchmarking and optimization for Big Data applications.
The pipeline is composed by several steps and only a part of them were designed for biological application: this allows us to apply (part of) the same method also on different topics with good results (see Appendix for further information about the analyses on non-biological data).


\end{document}
