\documentclass{standalone}

\begin{document}

\setbeamerfont{block body}{size=\scriptsize}
\setbeamerfont{block body example}{size=\scriptsize}
\setbeamerfont{block body alerted}{size=\scriptsize}
\setbeamertemplate{itemize/enumerate body begin}{\scriptsize}
\setbeamertemplate{itemize/enumerate subbody begin}{\scriptsize}

\begin{frame}{Deep Learning}{Neural Network models}

  \setbeamertemplate{itemize items}[ball]

  \scriptsize{Deep Learning model is becoming equivalent to Neural Network architecture/model, i.e a more or less complex pipeline of functions which takes in input a sample and it applies a series of transformations to obtain the desired result.}

  \begin{block}{Objectives}
    \begin{itemize}

      \item Optimization and extension of state-of-art Neural Network libraries;

      \item  Development of two novel libraries, for education and analytic purposes, respectively;

      \item Improve parallelization strategies to reach the best computational performances in cluster machine without GPUs supports;

    \end{itemize}

  \end{block}

  \begin{alertblock}{}
    All the algorithm and codes developed are \textbf{tested}, \textbf{documented} and \textbf{public available}!

    \quad

    \textbf{Reference:} \url{https://nico-curti2.gitbook.io/phd-thesis} (GitBook documentation).
  \end{alertblock}

\end{frame}


\setbeamertemplate{itemize/enumerate body begin}{\footnotesize}
\setbeamertemplate{itemize/enumerate subbody begin}{\footnotesize}

\begin{frame}{What is a Deep Learning model?}{Neural Network models}
  \setbeamertemplate{itemize items}[ball]

  \begin{itemize}
    \item Neural Networks are mathematical models \textbf{commonly used} in data analysis.

    \item From a theoretical point-of-view we can define a Neural Network as \textbf{a series of non-linear multi-parametric functions}.

    \item Neural Networks are considered as \textbf{Universal Function Approximators}.
  \end{itemize}

  \begin{figure}[hbp]
    \centering
    \includegraphics[width=0.85\textwidth]{net_scheme.png}
    \caption{\scriptsize{Neural Network model scheme.
             The model is composed by a series of layers made by interconnected computational units.
             The connections between layers can be serials or parallels and each layer models a pre-determined mathematical function.
             %The model parameters are tuned during the training procedure, i.e the model is fed with a series of labeled examples and its efficiency can be evaluated on new (test) data.
            }}
  \end{figure}

\end{frame}

\begin{frame}{State-of-art libraries}{Why other two libraries?}

  \scriptsize{A wide range of documentations and implementations have been written on Deep Learning and it is more and more hard to move around the different sources.}

  \scriptsize{Leader on this topic are became the multiple open-source `Python` libraries available on-line as \href{http://tensorflow.org}{Tensorflow}, \href{http://pytorch.org}{Pytorch} and \href{http://doi.acm.org/10.1145/2647868.2654889}{Caffe}.}

  \begin{columns}

    \begin{column}{0.5\textwidth}

      \begin{block}{Pros}
        \begin{itemize}
          \item[$\diamond$] Simplicity in writing complex models in a minimum number of code lines;
          \item[$\diamond$] Simplicity of the \textsf{Python} language;
          \item[$\diamond$] Extremely efficient in GPU environments;
        \end{itemize}
      \end{block}
    \end{column}
    \begin{column}{0.5\textwidth}

      \begin{alertblock}{Cons}
        \begin{itemize}
          \item[$\diamond$] Steep learning curve for complex applications or algorithm modifications;
          \item[$\diamond$] Hard to manage as services;
          \item[$\diamond$] They are not designed for CPU performances;
        \end{itemize}
      \end{alertblock}
    \end{column}

  \end{columns}

  \vspace{0.5cm}

  \scriptsize{Only a small part of the research community uses more deeper implementation in \textsf{C++} or other low-level programming languages.}
  \scriptsize{About them it should be mentioned the \textsf{darknet project} of Redmon J. et al. which created a sort of standard in object detection applications using a pure \textsf{Ansi-C} library.}

\end{frame}

\begin{frame}{NumPyNet \& Byron}{Why other two libraries?}

  \setbeamercolor{block title alerted}{fg=black, bg=orange!40!white}
  \setbeamercolor{block body alerted}{fg=black, bg=orange!20!white}

  \setbeamertemplate{itemize/enumerate body begin}{\tiny}
  \setbeamertemplate{itemize/enumerate subbody begin}{\tiny}

  \setbeamertemplate{itemize items}[ball]

  \begin{columns}

    \begin{column}{0.5\textwidth}
      \begin{block}{NumPyNet \hfill\includegraphics[width=.1\textwidth]{python.png}}
        \begin{itemize}
          \item \textbf{LANGUAGE:} \textsf{Python};
          \item \textbf{INSTALLATION:} \textsf{Setup} (\textsf{PyPI} upload wip);
          \item \textbf{OS:} Linux \& MacOS \& Windows;
          \item \textbf{DOCUMENTATION:} fully documented;
          \item \textbf{PURPOSE:} educational / study;
          \item \textbf{CI:} Travis \& Appveyor;
          \item \textbf{USAGE:} model design / algorithm improvements;
          \item \textbf{MISCELLANEOUS:} all functionality are tested against \textsf{Keras} counterpart;
          \item \textbf{URL:} \url{https://github.com/Nico-Curti/NumPyNet}
        \end{itemize}
      \end{block}
    \end{column}
    \begin{column}{0.5\textwidth}
      \begin{alertblock}{Byron \hfill\includegraphics[width=.1\textwidth]{cpp.png}}
        \begin{itemize}
          \item \textbf{LANGUAGE:} \textsf{C++} Standard 17;
          \item \textbf{INSTALLATION:} \textsf{CMake} \& \textsf{Make} \& \textsf{Docker};
          \item \textbf{OS:} Linux \& MacOS \& Windows;
          \item \textbf{DOCUMENTATION:} wide set of usage examples;
          \item \textbf{PURPOSE:} multi-threading CPU optimization;
          \item \textbf{CI:} Travis \& Appveyor \& CircleCI;
          \item \textbf{USAGE:} Super Resolution \& Object Detection \& Image Segmentation;
          \item \textbf{MISCELLANEOUS:} extension and optimization of the \textsf{darknet} project;
          \item \textbf{URL:} \url{https://github.com/Nico-Curti/Byron}
        \end{itemize}
      \end{alertblock}
    \end{column}

  \end{columns}

  \vspace{0.25cm}

  \scriptsize{From the union of this two project \textbf{Pyron} is born, i.e the completely wrap of the \textsf{Byron} library in \textsf{Python} using \textsf{Cython}.}

  \scriptsize{* Both libraries are already used in different works of thesis and research projects!}

\end{frame}

\begin{frame}{NumPyNet}{Neural Networks in Pure NumPy}

  \setbeamertemplate{itemize/enumerate body begin}{\scriptsize}
  \setbeamertemplate{itemize/enumerate subbody begin}{\scriptsize}

  \begin{block}{NumPyNet \hfill\includegraphics[width=0.02\textwidth]{python.png}}
    \begin{itemize}
      \item The library is written in pure \textsf{Python} and the only \textbf{external library} used is \href{http://www.numpy.org}{\textsf{Numpy}} (a based package for the scientific research).

      \item Despite all common libraries are correlated by a wide documentation is often difficult for novel users to move around the many hyper-links and papers cite in it.
      \textsf{NumPyNet} tries to overcome this problem with a \textbf{minimal mathematical documentation associated to each script} and a \textbf{wide range of comments inside the code}.

      \item Libraries like \textsf{Tensorflow} are efficient by a computational point-of-view and they have an extremely simple user interface.
      On the other hand the \textbf{deeper functionalities} of the code and the \textbf{implementation strategies} used \textbf{are unavoidably hidden behind tons of code lines}.
      In this way the user can performs complex computational tasks using the library as \textbf{black-box package}.
      \textsf{NumPyNet} wants to overcome this problem using \textbf{simple \textsf{Python} codes with extremely readability also for novel users} to better understand the symmetry between mathematical formulas and code.

      \item \textsf{NumPyNet} uses \textsf{Python} threads to easily manage independent tasks and optimize the computation.

    \end{itemize}
  \end{block}

  \vfill\scriptsize{* The library was developed in collaboration with Dott. Ceccarelli.}

\end{frame}

\begin{frame}{Byron}{Build YouR Own Neural Network}

  \setbeamercolor{block title alerted}{fg=black, bg=orange!40!white}
  \setbeamercolor{block body alerted}{fg=black, bg=orange!20!white}

  \setbeamertemplate{itemize/enumerate body begin}{\scriptsize}
  \setbeamertemplate{itemize/enumerate subbody begin}{\scriptsize}

  \begin{alertblock}{Byron \hfill\includegraphics[width=0.02\textwidth]{cpp.png}}
    \begin{itemize}
      \item The library is written in \textbf{pure \textsf{C++}} with the support of the modern standard 17.

      \item The library is \textbf{optimized for image processing} (probably the most common task in biomedical research).

      \item Starting from the \textsf{darknet project} backbone, \textsf{Byron} proposes \textbf{numerous improvements and fixes}.

      \item \textsf{Byron} works in a \textbf{fully parallel section} (\textsf{OpenMP}) in which each single computational function is performed using the full set of available cores. To further reduce the time of thread spawn and so optimize as much as possible the code performances, the library \textbf{works using a single parallel section} which is opened at the beginning of the computation and closed at the end.

      \item The library is also \textbf{completely wrapped} using \textsf{Cython} to enlarge the range of users also to the \textsf{Python} ones.

    \end{itemize}
  \end{alertblock}

  \vfill\scriptsize{* The library was developed in collaboration with Dott. Baroncini.}

\end{frame}


\begin{frame}<1>[label=tasks]{Applications}{Deep Learning model tasks}

  \setbeamercolor{block title}{fg=black, bg=NormalBlue}
  \setbeamercolor{block body}{fg=black, bg=LightBlue}

  \setbeamercolor{block title example}{fg=black, bg=DarkGreen!40!white}
  \setbeamercolor{block body example}{fg=black, bg=DarkGreen!20!white}
  \setbeamercolor{block title alerted}{fg=black, bg=orange!40!white}
  \setbeamercolor{block body alerted}{fg=black, bg=orange!20!white}

  \onslide<1->
  \begin{exampleblock}{Single Image Super Resolution}
    \begin{columns}
      \begin{column}{0.7\textwidth}
        \hspace*{0.25cm}
        \includegraphics[width=0.9\linewidth]{sr_example.png}
      \end{column}
      \begin{column}{0.3\textwidth}
        Improve spatial image resolution and reconstruction from low-resolution (LR) to high-resolution (HR).
      \end{column}
    \end{columns}
  \end{exampleblock}

  \begin{columns}
    \begin{column}{0.5\textwidth}

      \onslide<2->
      \begin{block}{Object Detection}
        \begin{columns}
          \begin{column}{0.5\textwidth}
            \hspace*{0.25cm}
            \includegraphics[width=\linewidth]{detection.png}
          \end{column}
          \begin{column}{0.5\textwidth}
            Identify single or multiple objects\\into a picture or video stream.
          \end{column}
        \end{columns}
      \end{block}


    \end{column}
    \begin{column}{0.5\textwidth}
      \onslide<3->
      \begin{alertblock}{Image Segmentation}
        \begin{columns}
          \begin{column}{0.5\textwidth}
            \hspace*{0.19cm}
            \includegraphics[width=1.15\linewidth]{segmentation.jpg}
          \end{column}
          \begin{column}{0.42\textwidth}
            Extract the exact pixels which belong to an object into a given image.
          \end{column}
        \end{columns}
      \end{alertblock}
    \end{column}
  \end{columns}

\end{frame}

\begin{frame}{Single Image Super Resolution}{What is Super Resolution?}

  \setbeamercolor{block title example}{fg=black, bg=DarkGreen!40!white}
  \setbeamercolor{block body example}{fg=black, bg=white}

  \scriptsize{We commonly think about Neural Network models as tools to \textbf{reduce} the problem dimensionality, i.e starting from high-dimensional data (e.g $w\times h\times c$ image) the model predicts a class (single number)}.

  \scriptsize{In the Super Resolution problem we have no classes but the desired output is a image.}
  \scriptsize{Single Image Super Resolution tasks starts from a image aiming to reconstruct its HR counterpart.}

  \setbeamertemplate{itemize items}[ball]

  \begin{exampleblock}{Super resolution procedure}
    \begin{itemize}

      \item We start from a prior-known HR image;
      \item We rescale this image obtaining its LR counterpart;
      \item We feed a super-resolution model with the LR image aiming to obtain in output its HR version;
      \item With the trained model we can re-apply the up-sampling procedure and further increase the HR quality*.

    \end{itemize}
  \end{exampleblock}

  \scriptsize{If this pipeline is performed feeding a Neural Network model using one-by-one a series of images, we talk about Single Image Super Resolution (SISR) algorithm.}

  \vspace{0.5cm}
  \scriptsize{* This is even more efficient if we think about a \textbf{zoom} procedure.}

\end{frame}

\begin{frame}{Standard up/down scaling algorithms}{Single Image Super Resolution}

  \setbeamertemplate{itemize items}[ball]

  \begin{columns}
    \begin{column}{0.4\textwidth}
      \scriptsize{Interpolation algorithms:}
      \begin{itemize}
        \item \textbf{Nearest};
        \item \textbf{Bicubic};
        \item \textbf{Lanczos};
      \end{itemize}

      \scriptsize{The best compromise between computation cost and efficiency is given by the Bicubic interpolation algorithm}.
      \scriptsize{Given a pixel, the interpolation function evaluates the 4 pixels around it applying a filter given by the equation:}
    \end{column}
    \begin{column}{0.6\textwidth}
      \begin{figure}
        \centering
        \def\svgwidth{\textwidth}
        \input{./img/up_down_sampling.pdf_tex}
        %\caption{\tiny{Up/Down sampling with scale factor equal to 2.}}
      \end{figure}
    \end{column}
  \end{columns}

  \
  \begin{equation*}
  \hspace{-0.75cm}\scriptsize{
  k(x) = \frac{1}{6} \left\{ \begin{array}{rc}
    (12 - 9B - 6C) |x|^3 + (-18 + 12B + 6C) |x|^2 + (6 - 2B)           & \mbox{if}        |x| < 1 \\
    (−B − 6C) |x|^3 + (6B + 30C) |x|^2 + (−12B − 48C) |x| + (8B + 24C) & \mbox{if} 1 \leq |x| < 2 \\
    0                                                                  & \mbox{otherwise}         \\
    \end{array}
    \right.
  }
  \end{equation*}
  \\
  \scriptsize{where $x$ identifies each pixel below the filter.}
  \scriptsize{Commonly values used for the filter parameters are $B=0$ and $C=0.75$ (used by \textsf{OpenCV} library) or $B=0$ and $C=0.5$ used by \textsf{Matlab}}.

  \scriptsize{\textbf{NOTE:} the nearest interpolation could be achieved also using \emph{Pooling} algorithm.}

\end{frame}


\begin{frame}{Image Quality}{Single Image Super Resolution}

  \setbeamercolor{block title}{fg=black, bg=NormalBlue}
  \setbeamercolor{block body}{fg=black, bg=white}

  \setbeamercolor{block title alerted}{fg=black, bg=orange!40!white}
  \setbeamercolor{block body alerted}{fg=black, bg=orange!20!white}

  \setbeamertemplate{itemize/enumerate body begin}{\scriptsize}
  \setbeamertemplate{itemize/enumerate subbody begin}{\scriptsize}

  \scriptsize{The most common image quality evaluator is given by our eyes.}

  \scriptsize{Quantitative evaluations:}

  \begin{columns}
    \begin{column}{0.4\textwidth}
      \hspace{-0.75cm}
      \begin{block}{PSNR - Peak Signal to Noise Ratio}
        \begin{itemize}
          \item It establishes the compression lossless of an image;

          \item Equation:

          \begin{equation*}
          \hspace{-0.75cm}
          PSNR = 20 \cdot \log_{10}\left( \frac{\max(I)}{\sqrt(MSE)} \right)
          \end{equation*}
          \\
          where $\max(I)$ is the maximum value which can be taken by a pixel in the image and $MSE$ is the Mean Square Error evaluated between the original and reconstructed images.
        \end{itemize}
      \end{block}
    \end{column}
    \begin{column}{0.65\textwidth}
      \begin{alertblock}{SSIM - Structural SIMilarity index}
        \begin{itemize}
          \item It evaluates the structural similarity between two images taking into account also the visible improvement seen by human eyes.

          \item Equation:

          \begin{equation*}
          \hspace{-0.75cm}
          SSIM(I, K) = \frac{1}{N}\sum_{i=1}^{N} \frac{(2\mu_x\mu_y + c_1)(2\sigma_{xy} + c_2)}{ ({\mu_x}^2 + {\mu_y}^2 + c_1)({\sigma_x}^2 + {\sigma_y}^2 + c_2) }
          \end{equation*}
          \\
          where $N$ is the number of arbitrary patches which divide the image and $c_1$ and $c_2$ parameters are fixed to avoid mathematical divergence.

        \end{itemize}
      \end{alertblock}

      \begin{tabular}{lcc}
        \hline \rowcolor{DarkGreen!20!white}
                          & \textbf{PSNR (dB)} & \textbf{SSIM ($\in [-1, 1]$)} \\
        \hline
        \textbf{Nearest}  & 25.118             & 0.847                         \\
        \textbf{Bicubic}  & 27.254             & 0.894                         \\
        \textbf{Lanczos}  & 26.566             & 0.871                         \\
        \hline
      \end{tabular}
    \end{column}

  \end{columns}

\end{frame}

\begin{frame}{EDSR - Enhanced Deep Super Resolution}{Super Resolution Models}
  \centering
  \includegraphics[width=0.78\linewidth]{compare.png}

  \setbeamercolor{block title alerted}{fg=black, bg=orange!40!white}
  \setbeamercolor{block body alerted}{fg=black, bg=white}

  \begin{alertblock}{Architecture}
    \scriptsize{
    \begin{tabular}{lccc}
      \hline \rowcolor{orange!20!white}
                               &  Channels     & Filter     & Number of    \\
      \rowcolor{orange!20!white}
      Layer                    & input/output  & dimensions & Parameters   \\
      \hline
      Conv. input              & 3/256      & $3\times3$   & 6912          \\
      Conv. (residual block)   & 256/256    & $3\times3$   & 589824        \\
      conv. (pre-shuffle)      & 256/256    & $3\times3$   & 589824        \\
      Conv. (upsample block)   & 256/1024   & $3\times3$   & 2359296       \\
      Conv. output             & 256/3      & $3\times3$   & 6912          \\
      \hline
    \end{tabular}
    }

    \vspace{0.5cm}
    \scriptsize{Average Time on $510\times339$ image: $576.92$~s.}

    \scriptsize{Winner of the \textbf{NTIRE 2017}. More than \textbf{3 million} of parameters!}
  \end{alertblock}

\end{frame}

\begin{frame}{WDSR - Wide Deep Super Resolution}{Super Resolution Models}
  \centering
  \includegraphics[width=0.7\linewidth]{SR_models.png}

  \setbeamercolor{block title}{fg=black, bg=NormalBlue}
  \setbeamercolor{block body}{fg=black, bg=white}

  \begin{block}{Architecture}
    \scriptsize{
    \begin{tabular}{lccc}
      \hline \rowcolor{NormalBlue}
                                  &  Channels     & Filter     & Number of    \\
      \rowcolor{NormalBlue}
      Layer                       & input/output  & dimensions & Parameters   \\
      \hline
      Conv. input 1               & 3/32       & $3\times3$   & 864     \\
      Conv. 1 (residual block)    & 32/192     & $3\times3$   & 55296   \\
      conv. 2 (residual block)    & 192/32     & $3\times3$   & 55296   \\
      Conv. (pre-shuffle)         & 32/48      & $3\times3$   & 13824   \\
      Conv. input 2 (pre-shuffle) & 3/48       & $5\times5$   & 3600    \\
      \hline
    \end{tabular}
    }

    \vspace{0.5cm}
    \scriptsize{Average Time on $510\times339$ image: $46.35$~s.}

    \scriptsize{Winner of the \textbf{NTIRE 2018}. $\sim100$K parameters, \textbf{less than $10\%$ of EDSR model}!}
  \end{block}

\end{frame}

\begin{frame}{Computational Performances}{Super Resolution Models}

  \scriptsize{Computational performances of WDSR model on $510\times339$ images ($100$ runs).}

  \scriptsize{Environment: Bioinformatics server grade machine (128 GB RAM memory and 2 CPU E5-2620, with 8 cores each.}

  \vfill
  \begin{columns}
    \begin{column}{0.6\textwidth}
      \includegraphics[width=\linewidth]{sr_threads.png}
    \end{column}
    \begin{column}{0.4\textwidth}
      \scriptsize{
      \begin{tabular}{cc}
        \hline \rowcolor{NormalBlue}
        \textbf{N° threads} & \textbf{Average Time (s)} \\
        \hline
         2                  & 403.478                   \\
         4                  & 219.268                   \\
         8                  & 122.986                   \\
        16                  & 78.571                    \\
        32                  & 46.348                    \\
        \hline
      \end{tabular}
      }

      \vspace{0.5cm}
      \scriptsize{\textbf{Sub-linear trend:}}

      \setbeamertemplate{itemize items}[ball]

      \begin{itemize}
        \item \scriptsize{Hyperthreading;}
        \item \scriptsize{NO affinity;}
      \end{itemize}
    \end{column}
  \end{columns}

\end{frame}


\begin{frame}{Quality Performances}{Super Resolution Models}

  \scriptsize{Evaluation of PSNR and SSIM on DIV2K validation set.}

  \begin{columns}
    \begin{column}{0.5\textwidth}
      \includegraphics[width=\linewidth]{sr_val_psnr.png}
    \end{column}
    \begin{column}{0.5\textwidth}
      \includegraphics[width=\linewidth]{sr_val_ssim.png}
    \end{column}
  \end{columns}

\end{frame}


\begin{frame}{Image Results}{Single Image Super Resolution}

  \begin{figure}
    \begin{overprint}
      \onslide<1>\centering\includegraphics[width=\linewidth]{./sr_res1.png}
      \onslide<2>\centering\includegraphics[width=\linewidth]{./sr_res2.png}
      \onslide<3>\centering\includegraphics[width=\linewidth]{./sr_res3.png}
    \end{overprint}
  \end{figure}

  \scriptsize{The model is trained on the \href{www.vision.ee.ethz.ch/~timofter/publications/Agustsson-CVPRW-2017.pdf}{\textbf{DIV2K}}(\emph{DIVerse 2K resolution high quality images}) dataset.}

  \scriptsize{The dataset contains 800 high-resolution images as training set and their corresponding low-resolution ones, obtained by different down-sampling methods and different scale factors (2, 3, and 4).}

\end{frame}


\begin{frame}{Model Extrapolation}{NMR Application}

  \scriptsize{Test on T1 weighted NMR images ($256\times 256$ $\rightarrow$ \textbf{REAL TIME}).}

  \scriptsize{The images were down-sampled ($128\times 128$ $\rightarrow$ 2x and $64\times 64$ $\rightarrow$ 4x) and then re-up-sampled.}

  \begin{figure}

    \begin{overprint}
      \onslide<1>\centering\includegraphics[width=0.8\linewidth]{./sr_brain_roi.png}
      \onslide<2>\centering\def\svgwidth{0.6\linewidth}\input{./img/sr_wow.pdf_tex}
    \end{overprint}

  \end{figure}

\end{frame}

\begin{frame}{Visual score}{NMR Application}

  \scriptsize{Test on T1 weighted NMR images ($256\times 256$ $\rightarrow$ \textbf{REAL TIME}).}

  \scriptsize{The images were down-sampled ($128\times 128$ $\rightarrow$ 2x and $64\times 64$ $\rightarrow$ 4x) and then re-up-sampled.}

  \centering\animategraphics[loop, controls, width=\linewidth]{10}{./gif/brain-}{10}{170}

\end{frame}

\begin{frame}{Quality score}{NMR Application}

  \scriptsize{Test on T1 weighted NMR images ($256\times 256$ $\rightarrow$ \textbf{REAL TIME}).}

  \scriptsize{The images were down-sampled ($128\times 128$ $\rightarrow$ 2x and $64\times 64$ $\rightarrow$ 4x) and then re-up-sampled with SR models.}

  \begin{figure}

    \begin{overprint}
      \onslide<1>\centering\def\svgwidth{\linewidth}\input{./img/sr_psnr_ssim_x2.pdf_tex}
      \onslide<2>\centering\def\svgwidth{\linewidth}\input{./img/sr_psnr_ssim_x4.pdf_tex}
    \end{overprint}

  \end{figure}

\end{frame}


\againframe<2>{tasks}

\begin{frame}{Object Detection}{What is Object Detection?}
  \setbeamertemplate{itemize items}[ball]

  \scriptsize{Object detection is one of the larger deep learning sub-discipline, especially when we talk about Neural Network models.}

  \scriptsize{This kind of problems aim to identify single or multiple objects into a picture or video stream.}

  \vspace{1cm}

  \begin{columns}
    \begin{column}{0.5\textwidth}
      \scriptsize{Possible applications:}

      \begin{itemize}
        \item \textbf{Object tracking};
        \item Video surveillance;
        \item \textbf{Pedestrian detection};
        \item Anomaly detection;
        \item \textbf{People counting};
        \item Self-driving cars;
        \item Face detection;
        \item $\cdots$;
      \end{itemize}

    \end{column}
    \begin{column}{0.5\textwidth}
      \includegraphics[width=\textwidth]{funny_detection.jpg}
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}{YOLO - You Only Look Once}{Object Detection Model}

  \scriptsize{YOLO is a deep Neural Network model with more than 100 layers and more than 62 million of parameters.}

  \scriptsize{The original implementation of the model is provided by Joseph Redmon (\url{https://github.com/pjreddie/darknet}) into the \textsf{darknet} project (\textsf{ANSI C}).}

  \begin{figure}
    \begin{overprint}
      \onslide<1>\centering\includegraphics[width=0.9\linewidth]{yolonet.png}
      \onslide<2>\centering\includegraphics[width=0.8\linewidth]{yolo_dog.png}
    \end{overprint}
  \end{figure}

\end{frame}


\begin{frame}{Computational Performances}{Object Detection Models}

  \scriptsize{\textsf{Byron} is inspired to \textsf{darknet} and its first implementation was about object detection task.}

  \scriptsize{\textsf{darknet} $\rightarrow$ benchmark $\rightarrow$ but its efficiency is based on GPU support!}

  \vfill
  \begin{columns}
    \begin{column}{0.6\textwidth}
      \scriptsize{Evaluation performed on 100 runs without multi-threading!}

      \def\svgwidth{\linewidth}\input{./img/byron_timing.pdf_tex}
    \end{column}
    \begin{column}{0.4\textwidth}
      \scriptsize{
      \begin{tabular}{cc}
        \hline \rowcolor{NormalBlue}
        \textbf{Framework} & \textbf{Average Time (s)} \\
        \hline
        \textbf{Byron}     & 5.18                      \\
        \textbf{darknet}   & 19.58                     \\
        \hline
      \end{tabular}
      }

      \vspace{0.5cm}
      \scriptsize{Time evaluated on $416\times 416$ images.}

      \scriptsize{Environment: Bioinformatics server grade machine (128 GB RAM memory and 2 CPU E5-2620, with 8 cores each.}
    \end{column}
  \end{columns}

\end{frame}



\begin{frame}{Model Extrapolation}{People counting Application}

  \scriptsize{Despite the model is incredibly efficient in object detection also with low quality images, there is a sort of \textbf{limit} in the number of pixels needed for object identification.}

  \scriptsize{We had the opportunity to empirically verify its limit working on a people tracking project for real time applications.}

  \scriptsize{The project was developed in collaboration with the Complex Systems (\textbf{PhySyCom}) group.}

  \begin{figure}
    \begin{overprint}
      \onslide<2>\centering\includegraphics[width=\linewidth]{yolo_people_sr.png}
      \onslide<3>\centering\includegraphics[width=\linewidth]{yolo_people_sr2.png}
    \end{overprint}
  \end{figure}

\end{frame}


\againframe<3>{tasks}

\begin{frame}{Image Segmentation}{What is Image Segmentation?}

  \scriptsize{\textbf{Object Detection:} give a label to \textbf{ROIs} of the input image.}

  \scriptsize{\textbf{Image Segmentation:} give a label to \textbf{each pixel} of the input image.}

  \vfill

  \centering\includegraphics[width=\linewidth]{segmentation_example.png}

\end{frame}


\begin{frame}{Image Segmentation in Medicine}{3D Femur Structure}

  \setbeamercolor{block body alerted}{fg=black, bg=white}

  \begin{alertblock}{Rizzoli Hospital project}
    \scriptsize{Improve the identification and segmentation of the femoral head, trying to discriminate this part of the bone from the articular cartilage and moreover from the acetabular fossa.}

    \vspace{0.5cm}
    \scriptsize{\textbf{Data type:} CT (\emph{Computer Tomography}) images.}

    \vspace{0.5cm}
    \scriptsize{\textbf{Dataset:} 4 (not-annotated) patients.}
  \end{alertblock}

  \setbeamertemplate{itemize items}[ball]

  \begin{columns}
    \begin{column}{0.5\linewidth}
      \scriptsize{\textbf{Semi-automatic pipeline:}}

      \begin{itemize}
        \item Edge enhancement;
        \item Thresholding;
        \item Morphological operations;
        \item Connected Components;
        \item Interpolation between consecutive frames;
      \end{itemize}

    \end{column}
    \begin{column}{0.5\linewidth}
      \centering\includegraphics[width=\linewidth]{3D_tool.png}
    \end{column}

  \end{columns}

\end{frame}

\begin{frame}{Image Segmentation in Medicine}{Segmentation Models}

  \scriptsize{The method is too naive to perform a good segmentation on the full set of slices.}
  \scriptsize{However, it can be useful to \textbf{reduce} the quantity of slices to annotate manually ($\sim400$ slices per patient)!}


  \centering\def\svgwidth{0.8\linewidth}\input{./img/segmentation_tool.pdf_tex}

  \scriptsize{Thus, we moved to a \textbf{Neural Network model}}

  \centering\includegraphics[width=0.8\linewidth]{./unet.png}

\end{frame}

\begin{frame}{U-Net Model}{Segmentation Models}
  \setbeamertemplate{itemize items}[ball]

  \begin{columns}
    \begin{column}{0.5\textwidth}

      \scriptsize{Training parameters:}
      \begin{itemize}
        \item Training Set: 96 images;
        \item Test Set: 40 images;
        \item Data augmentation:
              Rotated, shifted, mirrored.
        \item 40 epochs;
        \item loss: binary cross-entropy
        \item metrics: IoU (\emph{Intersection over Union})
      \end{itemize}

      \vspace{1cm}

      \scriptsize{\textbf{IoU Validation Set:}}

      \quad The $80\%$ of the test set has obtained a IoU score greater than $0.8$ and thus a good correspondence between our results and the ground truth.

    \end{column}
    \begin{column}{0.5\textwidth}
      \centering\includegraphics[width=\linewidth]{./loss.png}
    \end{column}
  \end{columns}

\end{frame}


\begin{frame}{IoU score}{Segmentation Models}

  \scriptsize{The model output were filtered using a thresholding of $10^{-2}$, i.e values $\leq$ were turned off.}

  \centering\def\svgwidth{\linewidth}\input{./img/IoU_score_out_good_logs_noaug.pdf_tex}

\end{frame}

\begin{frame}{3D Reconstruction}{Segmentation Models}

  \centering\animategraphics[loop, controls, width=\linewidth]{10}{./gif/bone-}{0}{45}

\end{frame}

\begin{frame}{Conclusion}{Deep Learning applications}

  \setbeamertemplate{itemize items}[ball]

  \begin{itemize}

    \item Two new libraries for Deep Learning applications were proposed:
      \begin{itemize}
        \item \textsf{NumPyNet}: a tool for educational practice and modeling;
        \item \textsf{Byron}: a tool for an efficient implementation of these models;
      \end{itemize}

    \item Both libraries implement cutting edge numerical techniques to maximize computation efficiency;

    \item \textsf{Byron} optimize and extend the \textsf{darknet} project with several fixes and computational improvements.

    \item \textsf{Byron} is able to join in a single framework either super resolution and object detection tasks.

    \item The results obtained using Super Resolution and Segmentation models are very promising for the analysis of biomedical images.

    \item We have shown that deep learning models are capable of a very efficient generalization due to their vast amount of parameters and a well-programmed training section.

    \item The \textsf{Byron} YOLO version is approximately 3.8x faster than \textsf{darknet} in all the simulations;

  \end{itemize}

\end{frame}


% ROSS= PROJECT
% \begin{frame}{Image Segmentation in Medicine}{ROSSO project}

%   \setbeamercolor{block body alerted}{fg=black, bg=white}
%   \setbeamertemplate{itemize items}[ball]

%   \begin{alertblock}{ROSSO - Robotic Ocular Semantic Segmentation for Ophthalmology}
%     \scriptsize{Sant'Orsola Hospital project: Extract the pixels belonging to sclera for the quantification of the red part of the image.}
%   \end{alertblock}

%   \begin{columns}
%     \begin{column}{0.3\linewidth}
%       \scriptsize{All the images have been manually annotated by experts.}
%       \scriptsize{Dataset:}
%       \begin{itemize}
%         \item Training: 150 images;
%         \item Test: 18 images;
%       \end{itemize}
%     \end{column}
%     \begin{column}{0.7\linewidth}
%       \begin{figure}
%         \begin{overprint}
%           \onslide<1>\centering\includegraphics[width=.8\linewidth]{sclera_seg1.png}
%           \onslide<2>\centering\includegraphics[width=.8\linewidth]{sclera_seg2.png}
%           \onslide<3>\centering\includegraphics[width=.8\linewidth]{sclera_seg3.png}
%         \end{overprint}
%       \end{figure}
%     \end{column}
%   \end{columns}

% \end{frame}

% \begin{frame}{Image Segmentation in Medicine}{ROSSO project}

%   \setbeamercolor{block body alerted}{fg=black, bg=white}

%   \begin{alertblock}{ROSSO - Robotic Ocular Semantic Segmentation for Ophthalmology}
%     \scriptsize{Sant'Orsola Hospital project: Extract the vascular network from the eye's sclera component.}
%   \end{alertblock}

%   \begin{figure}
%     \begin{overprint}
%       \onslide<1>\centering\includegraphics[width=.60\linewidth]{sclera_roi.png}
%       \onslide<2>\centering\includegraphics[width=.60\linewidth]{nefi_a_junius_ROI.png}
%     \end{overprint}
%   \end{figure}

% \end{frame}

\end{document}
