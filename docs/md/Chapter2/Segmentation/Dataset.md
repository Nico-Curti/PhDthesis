## Femur CT Dataset

The training of a deep Neural Network model as the U-Net one requires a large set of image with corresponding labels.
We developed some experiments on automatic segmentation into a (work in progress) project commissioned by the Rizzoli Hospital of Bologna.
The main task was to develop an automatic pipeline of image processing to extract the 3D femur structure starting from CT (*Computer Tomography*) images.
In particular the crucial point was to improve the identification and segmentation of the femoral head, trying to discriminate this part of the bone from the articular cartilage and moreover from the acetabular fossa.
The project was developed in collaboration with the Engineering group of the professor Viceconti and it aims to study the osteoporosis syndrome and its consequences.

In this work no data were provided by the Rizzoli Hospital and it is hard to find annotated biomedical images (public) on-line, especially about the region of our interest.
We found only few samples of femur CT images (4 patients) and these they are certainly not enough for an accurate training of the model.
To overcome this issue we applied a huge data augmentation pre-processing: each image was randomly rotated, shifted and mirrored.
Moreover we had to face on the problem of data annotation which is always a difficult and time expensive task: we did not have accurate medical annotation so we had to perform them by ourself.

![Naive segmentation pipeline applied to a series of CT slices. The thresholding algorithm combined with morphological operations allow to obtained a naive segmentation of the femur bone. The centroid of the segmented connected components is used to filter the false positive results. This pipeline was used to simplify the annotation procedure of the CT dataset.](../../../../img/3D_tool.png)

The annotation was performed using a semi-automatic approach.
We developed a custom image processing pipeline and we applied a combination of thresholding and morphological operators to extract as better as possible the bone structure from each CT frame.
The thresholding operation produced many false positive into the single image which had to be filtered.
To this purpose we could (reasonably) assume that the femur position does not change between two following images.
Thus, once the multiple pixel connected components were identified we filtered them according to their relative position into the image: each group of pixels obtained by the thresholding has its own centroid which remain quite the same also into the next slice (ref. Fig. [1](../../../../img/3D_tool.png)).
An interpolation of these components was performed to select only the femur components.
This method worked quite good when we considered the slices far from the femur head: when the acetabular fossa became very close the femur head the two components were not divided.
An example of this kind of issues is shown in Fig. [2](../../../../img/segmentation_tool.svg).

![Example of automatic segmentation using custom image processing pipeline. Starting from the bottom of femur bone the detection seems good but when the method starts to fail the failure is propagated to the next slices. The method is too naive to perform a good segmentation on the full set of slices. However, it can be useful to reduce the quantity of slices to annotate manually.](https://raw.githubusercontent.com/Nico-Curti/PhDthesis/master/img/segmentation_tool.svg?token=AF4CJX6CGR5SX3BRB36QGWK5WH4QQ&sanitize=true)

This naive approach for the image processing could not solve the full segmentation task but it can be considered as a good preliminary tool to produce annotated image.
With this approach we reduced the amount of required annotations by more than 50%.
The other part of the images were manually annotated.
The manual annotation was performed without any medical background and thus we can not ensure the goodness of our results.
This work only aims to prove the possibility of using deep learning techniques to face on segmentation problems.

Following this approach we were able to annotate 104 CT images randomly sampled from the 4 patient slices.
In particular we extracted 40 slices from a single patient and 96 from the remaining three.
In this way we could use the 96 images as training set (applying the told above image augmentation) and the 40 remaining slices as test set.
We chose to use a single patient slices as test set because with the output generated by the U-Net model we want to reconstruct the (approximated) 3D structure of the femur bone.


[**next >>**](./Results.md)